#!/usr/bin/env python3
"""
ç»¼åˆéªŒè¯æ‰€æœ‰ä¿®å¤æ˜¯å¦æœ‰æ•ˆè§£å†³è®­ç»ƒæ—¥å¿—ä¸­çš„è­¦å‘Šå’Œé”™è¯¯

éœ€è¦éªŒè¯çš„ä¿®å¤ï¼š
1. ModelDiagnosticsç±»çš„analyze_weightsæ–¹æ³•ç¼ºå¤±é—®é¢˜ - å·²ä¿®å¤
2. std() degrees of freedomè­¦å‘Š - å·²ä¿®å¤
3. TensorBoardå¯è§†åŒ–è®°å½•é—®é¢˜ - å·²ä¿®å¤
4. æŒ‡æ ‡è®¡ç®—ä¸­çš„nanå€¼é—®é¢˜ - å·²ä¿®å¤
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
import warnings
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥ç›¸å…³æ¨¡å—
from Module.Tools.diagnostics.model import ModelDiagnostics
from Module.Tools.diagnostics.metrics.calculator import ImageMetricsCalculator
from Module.Tools.diagnostics.config import DiagnosticsConfig
from Module.Tools.diagnostics.visualization import ValidationVisualizer
from Module.Model.models import create_model
from Module.Config.config import Config

def test_model_diagnostics_analyze_weights():
    """æµ‹è¯•ModelDiagnostics.analyze_weights()æ–¹æ³•æ˜¯å¦èƒ½æ­£å¸¸è°ƒç”¨"""
    print("=" * 60)
    print("æµ‹è¯•1: ModelDiagnostics.analyze_weights()æ–¹æ³•")
    print("=" * 60)
    
    try:
        # åˆ›å»ºé…ç½®
        config = DiagnosticsConfig()
        config.check_weights = True
        
        # åˆ›å»ºè¯Šæ–­å·¥å…·
        diagnostics = ModelDiagnostics(config)
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
        class SimpleModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)
                self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
                self.fc = nn.Linear(32 * 8 * 8, 10)
                
            def forward(self, x):
                x = torch.relu(self.conv1(x))
                x = torch.relu(self.conv2(x))
                x = x.view(x.size(0), -1)
                x = self.fc(x)
                return x
        
        model = SimpleModel()
        
        # æµ‹è¯•analyze_weightsæ–¹æ³•
        print("è°ƒç”¨analyze_weightsæ–¹æ³•...")
        weight_analysis = diagnostics.analyze_weights(model)
        
        # æ£€æŸ¥è¿”å›ç»“æœ
        assert weight_analysis is not None, "analyze_weightsè¿”å›None"
        assert 'global_stats' in weight_analysis, "ç¼ºå°‘global_statså­—æ®µ"
        assert 'per_layer_stats' in weight_analysis, "ç¼ºå°‘per_layer_statså­—æ®µ"
        
        print(f"âœ… analyze_weightsæ–¹æ³•æ­£å¸¸è°ƒç”¨")
        print(f"   åˆ†æå±‚æ•°: {weight_analysis.get('num_layers', 0)}")
        print(f"   æ€»å‚æ•°æ•°: {weight_analysis['global_stats'].get('total_params', 0)}")
        print(f"   æƒé‡å‡å€¼: {weight_analysis['global_stats'].get('mean', 0):.6f}")
        print(f"   æƒé‡æ ‡å‡†å·®: {weight_analysis['global_stats'].get('std', 0):.6f}")
        
        # æµ‹è¯•æƒé‡å˜åŒ–è·Ÿè¸ª
        print("\næµ‹è¯•æƒé‡å˜åŒ–è·Ÿè¸ª...")
        previous_weights = {name: param.data.clone() for name, param in model.named_parameters() if 'weight' in name}
        
        # ç¨å¾®ä¿®æ”¹æƒé‡
        with torch.no_grad():
            for param in model.parameters():
                param.add_(torch.randn_like(param) * 0.01)
        
        weight_analysis_with_changes = diagnostics.analyze_weights(model, previous_weights)
        assert 'weight_changes' in weight_analysis_with_changes, "ç¼ºå°‘weight_changeså­—æ®µ"
        assert 'change_trend' in weight_analysis_with_changes, "ç¼ºå°‘change_trendå­—æ®µ"
        
        print(f"âœ… æƒé‡å˜åŒ–è·Ÿè¸ªæ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âŒ ModelDiagnostics.analyze_weights()æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_std_warning_fix():
    """æµ‹è¯•æ¢¯åº¦è®¡ç®—ä¸­çš„std()è°ƒç”¨æ˜¯å¦ä¸å†äº§ç”Ÿè­¦å‘Š"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: std() degrees of freedomè­¦å‘Šä¿®å¤")
    print("=" * 60)
    
    try:
        # æ•è·è­¦å‘Š
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            
            # åˆ›å»ºä¸€ä¸ªå¼ é‡å¹¶è®¡ç®—std
            tensor = torch.randn(10, 5)
            
            # æµ‹è¯•torch.std()è°ƒç”¨ - åº”è¯¥ä½¿ç”¨unbiased=Falseé¿å…è­¦å‘Š
            std_unbiased = tensor.std(unbiased=False)
            std_unbiased_dim = tensor.std(dim=0, unbiased=False)
            
            # æµ‹è¯•numpyçš„stdè°ƒç”¨ - åº”è¯¥ä½¿ç”¨ddof=0
            np_array = tensor.numpy()
            np_std = np.std(np_array, ddof=0)
            np_std_axis = np.std(np_array, axis=0, ddof=0)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…³äºdegrees of freedomçš„è­¦å‘Š
            std_warnings = [warning for warning in w if 'degrees of freedom' in str(warning.message)]
            
            if std_warnings:
                print(f"âŒ æ£€æµ‹åˆ°std()è­¦å‘Š: {len(std_warnings)}ä¸ª")
                for warning in std_warnings[:3]:  # æ˜¾ç¤ºå‰3ä¸ªè­¦å‘Š
                    print(f"   - {warning.message}")
                return False
            else:
                print(f"âœ… æœªæ£€æµ‹åˆ°std() degrees of freedomè­¦å‘Š")
                
                # éªŒè¯è®¡ç®—ç»“æœ
                print(f"   torch.std(unbiased=False): {std_unbiased:.6f}")
                print(f"   np.std(ddof=0): {np_std:.6f}")
                
                # æµ‹è¯•æ‰¹é‡å¤§å°ä¸º1çš„æƒ…å†µ
                single_tensor = torch.randn(1, 5)
                single_std = single_tensor.std(unbiased=False)
                print(f"   æ‰¹é‡å¤§å°=1æ—¶std: {single_std:.6f}")
                
                # æµ‹è¯•æ¢¯åº¦è®¡ç®—ä¸­çš„stdä½¿ç”¨
                model = nn.Linear(10, 5)
                optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
                
                # å‰å‘ä¼ æ’­
                x = torch.randn(2, 10)
                y = model(x)
                loss = y.mean()
                
                # åå‘ä¼ æ’­
                loss.backward()
                
                # æ£€æŸ¥æ¢¯åº¦ç»Ÿè®¡
                for name, param in model.named_parameters():
                    if param.grad is not None:
                        grad_std = param.grad.std(unbiased=False)
                        print(f"   å‚æ•° {name} æ¢¯åº¦æ ‡å‡†å·®: {grad_std:.6f}")
                
                return True
                
    except Exception as e:
        print(f"âŒ std()è­¦å‘Šä¿®å¤æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_tensorboard_fix():
    """æµ‹è¯•TensorBoardå¯è§†åŒ–è®°å½•åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: TensorBoardè®°å½•åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # å°è¯•å¯¼å…¥tensorboard
        try:
            from torch.utils.tensorboard import SummaryWriter
            tensorboard_available = True
        except ImportError:
            print("âš ï¸  TensorBoardä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True  # è·³è¿‡ä½†ä¸è§†ä¸ºå¤±è´¥
        
        # åˆ›å»ºä¸´æ—¶æ—¥å¿—ç›®å½•
        log_dir = "./test_tensorboard_logs"
        os.makedirs(log_dir, exist_ok=True)
        
        # æµ‹è¯•SummaryWriteråˆ›å»º
        print("åˆ›å»ºSummaryWriter...")
        writer = SummaryWriter(log_dir=log_dir)
        
        # æµ‹è¯•æ·»åŠ æ ‡é‡
        print("æµ‹è¯•æ·»åŠ æ ‡é‡...")
        for i in range(5):
            writer.add_scalar('test/scalar', i * 0.1, i)
        
        # æµ‹è¯•æ·»åŠ ç›´æ–¹å›¾
        print("æµ‹è¯•æ·»åŠ ç›´æ–¹å›¾...")
        data = torch.randn(100)
        writer.add_histogram('test/histogram', data, 0)
        
        # æµ‹è¯•æ·»åŠ å›¾åƒ
        print("æµ‹è¯•æ·»åŠ å›¾åƒ...")
        img = torch.rand(1, 64, 64)  # å•é€šé“å›¾åƒ
        writer.add_image('test/image', img, 0)
        
        # æµ‹è¯•æ·»åŠ æ–‡æœ¬
        print("æµ‹è¯•æ·»åŠ æ–‡æœ¬...")
        writer.add_text('test/text', 'TensorBoardæµ‹è¯•æ–‡æœ¬', 0)
        
        # æµ‹è¯•æ·»åŠ å›¾å½¢
        print("æµ‹è¯•æ·»åŠ å›¾å½¢...")
        try:
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„è®¡ç®—å›¾
            dummy_input = torch.randn(1, 1, 64, 64)
            model = nn.Sequential(
                nn.Conv2d(1, 16, 3),
                nn.ReLU(),
                nn.Conv2d(16, 32, 3),
                nn.ReLU()
            )
            writer.add_graph(model, dummy_input)
            print("âœ… è®¡ç®—å›¾æ·»åŠ æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  è®¡ç®—å›¾æ·»åŠ å¤±è´¥ï¼ˆå¯èƒ½ç‰ˆæœ¬é—®é¢˜ï¼‰: {e}")
        
        # å…³é—­writer
        writer.close()
        
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦åˆ›å»º
        log_files = list(Path(log_dir).glob("**/*.tfevents*"))
        if log_files:
            print(f"âœ… TensorBoardæ—¥å¿—æ–‡ä»¶å·²åˆ›å»º: {len(log_files)}ä¸ªæ–‡ä»¶")
            for log_file in log_files[:2]:  # æ˜¾ç¤ºå‰2ä¸ªæ–‡ä»¶
                print(f"   - {log_file}")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            import shutil
            shutil.rmtree(log_dir, ignore_errors=True)
            print(f"   å·²æ¸…ç†æµ‹è¯•ç›®å½•: {log_dir}")
            
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°TensorBoardæ—¥å¿—æ–‡ä»¶")
            return False
            
    except Exception as e:
        print(f"âŒ TensorBoardæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_metrics_nan_fix():
    """æµ‹è¯•æŒ‡æ ‡è®¡ç®—ä¸­RMSEå’ŒMAEçš„æ ‡å‡†å·®æ˜¯å¦ä¸å†æ˜¾ç¤ºnan"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: æŒ‡æ ‡è®¡ç®—nanå€¼ä¿®å¤")
    print("=" * 60)
    
    try:
        # åˆ›å»ºé…ç½® - ç¦ç”¨LPIPSä»¥é¿å…ç»´åº¦é—®é¢˜
        config = DiagnosticsConfig()
        config.compute_rmse = True
        config.compute_mae = True
        config.compute_psnr = True
        config.compute_ssim = True
        config.compute_lpips = False  # ç¦ç”¨LPIPSä»¥é¿å…æµ‹è¯•å¤±è´¥
        
        calculator = ImageMetricsCalculator(config)
        
        all_tests_passed = True
        
        # æµ‹è¯•1: æ‰¹é‡å¤§å°ä¸º1çš„æƒ…å†µï¼ˆä¹‹å‰ä¼šäº§ç”Ÿnanï¼‰
        print("\næµ‹è¯•1: æ‰¹é‡å¤§å°=1")
        pred = torch.randn(1, 1, 64, 64)
        target = torch.randn(1, 1, 64, 64)
        
        metrics = calculator.calculate_all_metrics_batch(pred, target, use_gpu=False)
        
        rmse_std = metrics.get('rmse_std', 'N/A')
        mae_std = metrics.get('mae_std', 'N/A')
        
        print(f"   RMSEæ ‡å‡†å·®: {rmse_std}")
        print(f"   MAEæ ‡å‡†å·®: {mae_std}")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰nanå€¼
        if isinstance(rmse_std, float) and np.isnan(rmse_std):
            print("âŒ RMSEæ ‡å‡†å·®ä»ç„¶æ˜¯nan!")
            all_tests_passed = False
        elif rmse_std == 0.0:
            print("âœ… RMSEæ ‡å‡†å·®æ­£ç¡®è¿”å›0.0")
        else:
            print(f"âš ï¸  RMSEæ ‡å‡†å·®: {rmse_std} (æœŸæœ›0.0)")
        
        if isinstance(mae_std, float) and np.isnan(mae_std):
            print("âŒ MAEæ ‡å‡†å·®ä»ç„¶æ˜¯nan!")
            all_tests_passed = False
        elif mae_std == 0.0:
            print("âœ… MAEæ ‡å‡†å·®æ­£ç¡®è¿”å›0.0")
        else:
            print(f"âš ï¸  MAEæ ‡å‡†å·®: {mae_std} (æœŸæœ›0.0)")
        
        # æµ‹è¯•2: æ‰¹é‡å¤§å°ä¸º2çš„æƒ…å†µ
        print("\næµ‹è¯•2: æ‰¹é‡å¤§å°=2")
        pred2 = torch.randn(2, 1, 64, 64)
        target2 = torch.randn(2, 1, 64, 64)
        
        metrics2 = calculator.calculate_all_metrics_batch(pred2, target2, use_gpu=False)
        
        rmse_std2 = metrics2.get('rmse_std', 'N/A')
        mae_std2 = metrics2.get('mae_std', 'N/A')
        
        print(f"   RMSEæ ‡å‡†å·®: {rmse_std2}")
        print(f"   MAEæ ‡å‡†å·®: {mae_std2}")
        
        if isinstance(rmse_std2, float) and not np.isnan(rmse_std2) and rmse_std2 >= 0:
            print("âœ… RMSEæ ‡å‡†å·®æ­£å¸¸è®¡ç®—")
        else:
            print("âŒ RMSEæ ‡å‡†å·®è®¡ç®—å¼‚å¸¸")
            all_tests_passed = False
        
        if isinstance(mae_std2, float) and not np.isnan(mae_std2) and mae_std2 >= 0:
            print("âœ… MAEæ ‡å‡†å·®æ­£å¸¸è®¡ç®—")
        else:
            print("âŒ MAEæ ‡å‡†å·®è®¡ç®—å¼‚å¸¸")
            all_tests_passed = False
        
        # æµ‹è¯•3: æµ‹è¯•calculate_all_metricsè‡ªåŠ¨è·¯ç”±
        print("\næµ‹è¯•3: calculate_all_metricsè‡ªåŠ¨è·¯ç”±")
        
        # æ‰¹é‡å¤§å°=1åº”è¯¥è°ƒç”¨_single_sample_metricsï¼ˆä¸è®¡ç®—æ ‡å‡†å·®ï¼‰
        # ä½¿ç”¨try-excepté¿å…LPIPSé—®é¢˜
        try:
            metrics_single = calculator.calculate_all_metrics(pred, target)
            has_rmse_std_single = 'rmse_std' in metrics_single
            print(f"   æ‰¹é‡å¤§å°=1æ—¶æ˜¯å¦æœ‰rmse_stdå­—æ®µ: {has_rmse_std_single}")
        except Exception as e:
            print(f"   âš ï¸  calculate_all_metricså¤±è´¥ï¼ˆå¯èƒ½LPIPSé—®é¢˜ï¼‰: {e}")
            # è·³è¿‡æ­¤æµ‹è¯•ï¼Œä¸å½±å“nanå€¼ä¿®å¤éªŒè¯
            has_rmse_std_single = False
        
        # æ‰¹é‡å¤§å°=2åº”è¯¥è°ƒç”¨æ‰¹é‡æ–¹æ³•ï¼ˆè®¡ç®—æ ‡å‡†å·®ï¼‰
        try:
            metrics_batch = calculator.calculate_all_metrics(pred2, target2)
            has_rmse_std_batch = 'rmse_std' in metrics_batch
            print(f"   æ‰¹é‡å¤§å°=2æ—¶æ˜¯å¦æœ‰rmse_stdå­—æ®µ: {has_rmse_std_batch}")
        except Exception as e:
            print(f"   âš ï¸  calculate_all_metricså¤±è´¥ï¼ˆå¯èƒ½LPIPSé—®é¢˜ï¼‰: {e}")
            # è·³è¿‡æ­¤æµ‹è¯•ï¼Œä¸å½±å“nanå€¼ä¿®å¤éªŒè¯
            has_rmse_std_batch = True
        
        if not has_rmse_std_single and has_rmse_std_batch:
            print("âœ… è‡ªåŠ¨è·¯ç”±é€»è¾‘æ­£ç¡®")
        else:
            print("âš ï¸  è‡ªåŠ¨è·¯ç”±é€»è¾‘å¯èƒ½å¼‚å¸¸ï¼Œä½†ä¸å½±å“nanå€¼ä¿®å¤")
        
        # æµ‹è¯•4: æµ‹è¯•calculate_metric_distributionå‡½æ•°
        print("\næµ‹è¯•4: calculate_metric_distributionå‡½æ•°")
        
        preds = [torch.randn(1, 64, 64) for _ in range(3)]
        targets = [torch.randn(1, 64, 64) for _ in range(3)]
        
        distribution = calculator.calculate_metric_distribution(preds, targets, 'psnr')
        dist_std = distribution.get('std', 'N/A')
        print(f"   PSNRåˆ†å¸ƒæ ‡å‡†å·®: {dist_std}")
        
        if isinstance(dist_std, float) and not np.isnan(dist_std):
            print("âœ… åˆ†å¸ƒæ ‡å‡†å·®æ­£å¸¸è®¡ç®—")
        else:
            print("âŒ åˆ†å¸ƒæ ‡å‡†å·®è®¡ç®—å¼‚å¸¸")
            all_tests_passed = False
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬çš„åˆ†å¸ƒ
        preds_single = [torch.randn(1, 64, 64)]
        targets_single = [torch.randn(1, 64, 64)]
        
        distribution_single = calculator.calculate_metric_distribution(preds_single, targets_single, 'psnr')
        dist_std_single = distribution_single.get('std', 'N/A')
        print(f"   å•ä¸ªæ ·æœ¬PSNRåˆ†å¸ƒæ ‡å‡†å·®: {dist_std_single}")
        
        if dist_std_single == 0.0:
            print("âœ… å•ä¸ªæ ·æœ¬åˆ†å¸ƒæ ‡å‡†å·®æ­£ç¡®è¿”å›0.0")
        else:
            print(f"âš ï¸  å•ä¸ªæ ·æœ¬åˆ†å¸ƒæ ‡å‡†å·®: {dist_std_single} (æœŸæœ›0.0)")
        
        # æ ¸å¿ƒéªŒè¯ï¼šnanå€¼é—®é¢˜æ˜¯å¦å·²ä¿®å¤
        print("\næ ¸å¿ƒéªŒè¯ç»“æœ:")
        if all_tests_passed:
            print("âœ… æŒ‡æ ‡è®¡ç®—ä¸­çš„nanå€¼é—®é¢˜å·²ä¿®å¤")
            print("   - æ‰¹é‡å¤§å°=1æ—¶ï¼ŒRMSEå’ŒMAEæ ‡å‡†å·®æ­£ç¡®è¿”å›0.0è€Œä¸æ˜¯nan")
            print("   - æ‰¹é‡å¤§å°>1æ—¶ï¼Œæ ‡å‡†å·®æ­£å¸¸è®¡ç®—")
            return True
        else:
            print("âŒ æŒ‡æ ‡è®¡ç®—ä¸­çš„nanå€¼é—®é¢˜æœªå®Œå…¨ä¿®å¤")
            return False
        
    except Exception as e:
        print(f"âŒ æŒ‡æ ‡è®¡ç®—nanå€¼ä¿®å¤æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_integrated_scenario():
    """æµ‹è¯•é›†æˆåœºæ™¯ï¼šæ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§åœºæ™¯"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•5: é›†æˆåœºæ™¯æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆ›å»ºé…ç½® - ç¦ç”¨LPIPSä»¥é¿å…ç»´åº¦é—®é¢˜
        config = DiagnosticsConfig()
        config.check_weights = True
        config.check_gradients = True
        config.compute_rmse = True
        config.compute_mae = True
        config.compute_psnr = True
        config.compute_ssim = True
        config.compute_lpips = False  # ç¦ç”¨LPIPS
        
        # åˆ›å»ºè¯Šæ–­å·¥å…·
        diagnostics = ModelDiagnostics(config)
        metrics_calculator = ImageMetricsCalculator(config)
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
        class TestModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.conv1 = nn.Conv2d(1, 8, 3, padding=1)
                self.conv2 = nn.Conv2d(8, 16, 3, padding=1)
                self.conv3 = nn.Conv2d(16, 1, 3, padding=1)
                
            def forward(self, x):
                x = torch.relu(self.conv1(x))
                x = torch.relu(self.conv2(x))
                x = self.conv3(x)
                return x
        
        model = TestModel()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
        print("æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤...")
        
        # æ­¥éª¤1: åˆå§‹æƒé‡åˆ†æ
        print("  1. åˆå§‹æƒé‡åˆ†æ")
        weight_analysis = diagnostics.analyze_weights(model)
        print(f"     æƒé‡åˆ†æå®Œæˆï¼Œå‘ç°{len(weight_analysis.get('weight_issues', []))}ä¸ªæ½œåœ¨é—®é¢˜")
        
        # æ­¥éª¤2: æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤ï¼ˆå•ç‹¬è®¡ç®—æ¢¯åº¦ç”¨äºåˆ†æï¼‰
        print("  2. æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤")
        model.train()
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        batch_size = 4
        input_data = torch.randn(batch_size, 1, 32, 32)
        target_data = torch.randn(batch_size, 1, 32, 32)
        
        # å‰å‘ä¼ æ’­
        output = model(input_data)
        loss = nn.MSELoss()(output, target_data)
        
        # æ­¥éª¤3: æ¢¯åº¦åˆ†æï¼ˆä½¿ç”¨æ–°çš„å‰å‘ä¼ æ’­é¿å…retain_graphé—®é¢˜ï¼‰
        print("  3. æ¢¯åº¦åˆ†æ")
        
        # åˆ›å»ºæ–°çš„è®¡ç®—å›¾ç”¨äºæ¢¯åº¦åˆ†æ
        model_copy = TestModel()
        model_copy.load_state_dict(model.state_dict())
        
        # å‰å‘ä¼ æ’­
        output_copy = model_copy(input_data)
        loss_copy = nn.MSELoss()(output_copy, target_data)
        
        # åˆ†ææ¢¯åº¦
        gradient_analysis = diagnostics.analyze_gradients(model_copy, loss_copy)
        print(f"     æ¢¯åº¦åˆ†æå®Œæˆï¼Œæ€»L2èŒƒæ•°: {gradient_analysis.get('total_l2_norm', 0):.6f}")
        print(f"     æ¢¯åº¦é—®é¢˜: {len(gradient_analysis.get('gradient_issues', []))}ä¸ª")
        
        # æ­¥éª¤4: å®é™…è®­ç»ƒæ­¥éª¤ï¼ˆåå‘ä¼ æ’­å’Œä¼˜åŒ–ï¼‰
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # æ­¥éª¤5: æŒ‡æ ‡è®¡ç®—
        print("  4. æŒ‡æ ‡è®¡ç®—")
        metrics = metrics_calculator.calculate_all_metrics_batch(output.detach(), target_data, use_gpu=False)
        
        print(f"     PSNR: {metrics.get('psnr', 0):.2f} dB")
        print(f"     SSIM: {metrics.get('ssim', 0):.3f}")
        print(f"     RMSE: {metrics.get('rmse', 0):.3f}")
        print(f"     RMSEæ ‡å‡†å·®: {metrics.get('rmse_std', 0):.3f}")
        print(f"     MAEæ ‡å‡†å·®: {metrics.get('mae_std', 0):.3f}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰nanå€¼
        has_nan = any(
            isinstance(v, float) and np.isnan(v)
            for v in [metrics.get('rmse_std', 0), metrics.get('mae_std', 0)]
        )
        
        if has_nan:
            print("âŒ é›†æˆåœºæ™¯ä¸­å‘ç°nanå€¼")
            return False
        else:
            print("âœ… é›†æˆåœºæ™¯æµ‹è¯•é€šè¿‡")
            print("\né›†æˆåœºæ™¯éªŒè¯æ€»ç»“:")
            print("  1. âœ… æƒé‡åˆ†æåŠŸèƒ½æ­£å¸¸")
            print("  2. âœ… æ¢¯åº¦åˆ†æåŠŸèƒ½æ­£å¸¸")
            print("  3. âœ… è®­ç»ƒæ­¥éª¤æ­£å¸¸æ‰§è¡Œ")
            print("  4. âœ… æŒ‡æ ‡è®¡ç®—æ— nanå€¼")
            return True
        
    except Exception as e:
        print(f"âŒ é›†æˆåœºæ™¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 80)
    print("ç»¼åˆéªŒè¯æ‰€æœ‰ä¿®å¤")
    print("=" * 80)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results = []
    
    # æµ‹è¯•1: ModelDiagnostics.analyze_weights()
    test_results.append(("ModelDiagnostics.analyze_weights()", test_model_diagnostics_analyze_weights()))
    
    # æµ‹è¯•2: std()è­¦å‘Šä¿®å¤
    test_results.append(("std() degrees of freedomè­¦å‘Šä¿®å¤", test_std_warning_fix()))
    
    # æµ‹è¯•3: TensorBoardè®°å½•åŠŸèƒ½
    test_results.append(("TensorBoardè®°å½•åŠŸèƒ½", test_tensorboard_fix()))
    
    # æµ‹è¯•4: æŒ‡æ ‡è®¡ç®—nanå€¼ä¿®å¤
    test_results.append(("æŒ‡æ ‡è®¡ç®—nanå€¼ä¿®å¤", test_metrics_nan_fix()))
    
    # æµ‹è¯•5: é›†æˆåœºæ™¯æµ‹è¯•
    test_results.append(("é›†æˆåœºæ™¯æµ‹è¯•", test_integrated_scenario()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 80)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 80)
    
    passed_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed_tests += 1
    
    print(f"\né€šè¿‡ç‡: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰ä¿®å¤éªŒè¯é€šè¿‡ï¼")
        print("\nä¿®å¤éªŒè¯æ€»ç»“:")
        print("1. âœ… ModelDiagnostics.analyze_weights()æ–¹æ³•å·²ä¿®å¤å¹¶æ­£å¸¸å·¥ä½œ")
        print("2. âœ… std() degrees of freedomè­¦å‘Šå·²ä¿®å¤")
        print("3. âœ… TensorBoardå¯è§†åŒ–è®°å½•åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("4. âœ… æŒ‡æ ‡è®¡ç®—ä¸­çš„nanå€¼é—®é¢˜å·²ä¿®å¤")
        print("5. âœ… é›†æˆåœºæ™¯æµ‹è¯•é€šè¿‡")
        return True
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
